{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caiocmello/netzdg/blob/main/NetzDG_colours.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZKfLUw_sOlC"
      },
      "source": [
        "This notebook has been built to analyse orange, red, green and grey clusters\n",
        "\n",
        "Dataset: df_colours.csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGtTw7YVxspv"
      },
      "source": [
        "### Install and import: Run this cell to load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh0qX7uSsGMP"
      },
      "outputs": [],
      "source": [
        "# @title Load Libraries and Data\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import spacy\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import re\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "from spacy.lang.en.stop_words import STOP_WORDS as en_stopwords\n",
        "from spacy.lang.de.stop_words import STOP_WORDS as de_stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import ngrams\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "# Load the data frame into colab\n",
        "df = pd.read_csv('df_colours.csv')\n",
        "df = df[['tweet_id', 'user_username', 'text', 'retweet_count', 'like_count', 'created_at', 'cluster']]\n",
        "df.set_index('tweet_id', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVA7CXREtPhY",
        "outputId": "d56fc10f-f10d-437e-95fa-601398309c8a"
      },
      "outputs": [],
      "source": [
        "# @title Run this cell to see the list of users in dataframe and the number of tweets they posted\n",
        "df['user_username'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "1oyM2WaXtgc3",
        "outputId": "7836ead7-8b26-49a5-fc98-2f455e48b740"
      },
      "outputs": [],
      "source": [
        "# @title Choose a user to see tweets written by them\n",
        "user = \"fdp\" # @param {type:\"string\"} # Define word here\n",
        "\n",
        "# See only tweets written by @user\n",
        "\n",
        "def show_rows_with_user(df, user):\n",
        "\n",
        "  return df[df['user_username'] == user]\n",
        "\n",
        "result = show_rows_with_user(df, user)\n",
        "result = result.sort_values(by=['retweet_count'], ascending=False)\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEIgamYstreD"
      },
      "source": [
        "### List of n-grams\n",
        "\n",
        "* **user:** *user name*\n",
        "* **cluster:** blue or purple\n",
        "* **content:** all, per_user or per_cluster\n",
        "* **items_in_list:** *number*\n",
        "* **see_top_words:** unigrams or bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNchmwfAtlgh",
        "outputId": "8f689647-34c8-4183-80f6-e3df39ca885d"
      },
      "outputs": [],
      "source": [
        "# @title Set parameters to see list of n-grams\n",
        "\n",
        "\n",
        "df_NetzClean = df.copy()\n",
        "\n",
        "# Remove underscore from tweets (To avoid erros in deleting users like @balzer_sascha)\n",
        "\n",
        "def cleaner(text):\n",
        "    text = re.sub(r\"_\", \"\", text) # Remove underscore\n",
        "    return text\n",
        "df_NetzClean['text_clean'] = df_NetzClean['text'].map(lambda x: cleaner(x))\n",
        "\n",
        "# Remove users, remove URLs, remove hashtag sign\n",
        "\n",
        "def cleaner(text):\n",
        "    text = re.sub(\"@[A-Za-z0-9]+\",\"\",text) # Remove @ sign\n",
        "    text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", text) # Remove http links\n",
        "    text = \" \".join(text.split())\n",
        "    text = text.replace(\"#\", \"\") # Remove hashtag sign but keep the text\n",
        "    return text\n",
        "df_NetzClean['text_clean'] = df_NetzClean['text'].map(lambda x: cleaner(x))\n",
        "\n",
        "df_NetzClean = df_NetzClean.drop_duplicates(subset=['text']) #remove duplicated tweets in column 'text'\n",
        "\n",
        "def get_top_n_words(corpus, stopwords, n=20):\n",
        "    vec = CountVectorizer(stop_words = stopwords).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "\n",
        "def get_top_n_bigram(corpus, stopwords, n=20):\n",
        "    vec = CountVectorizer(ngram_range=(2, 2), stop_words = stopwords).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "\n",
        "def get_top_n_words_tfidf(corpus, stopwords, n=20):\n",
        "    vec = TfidfVectorizer(stop_words = stopwords).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "\n",
        "def get_top_n_bigram_tfidf(corpus, stopwords, n=20):\n",
        "    vec = TfidfVectorizer(ngram_range=(2, 2), stop_words = stopwords).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "\n",
        "# Transform stopwords in a list\n",
        "\n",
        "stopwords_de = list(de_stopwords)\n",
        "stopwords_en = list(en_stopwords)\n",
        "\n",
        "stopwords = stopwords_de + stopwords_en #create a mixed list of stopwords (German and English)\n",
        "\n",
        "# Edit your list of stopwords manually\n",
        "\n",
        "add_to_stopwords = ['rt']\n",
        "stopwords = stopwords + add_to_stopwords\n",
        "\n",
        "# Define content\n",
        "user = 'fdp' # @param {type:\"string\"}\n",
        "cluster = 'orange' # @param {type:\"string\"}\n",
        "all = df_NetzClean[['text_clean']]\n",
        "df_user = df_NetzClean[df_NetzClean['user_username'] == user]\n",
        "per_user = df_user[['text_clean']]\n",
        "df_cluster = df_NetzClean[df_NetzClean['cluster'] == cluster]\n",
        "per_cluster = df_cluster[['text_clean']]\n",
        "\n",
        "content = per_cluster # @param {type:\"raw\"}\n",
        "content.reset_index(drop=True, inplace=True)\n",
        "content = content.values.tolist()\n",
        "\n",
        "string = '\\n'.join(str(e) for e in content)\n",
        "\n",
        "items_in_list = 10 # @param {type:\"number\"}\n",
        "\n",
        "unigrams = get_top_n_words([string], stopwords=stopwords, n=items_in_list)\n",
        "bigrams = get_top_n_bigram([string], stopwords=stopwords, n=items_in_list)\n",
        "see_top_words = bigrams # @param {type:\"raw\"}\n",
        "\n",
        "see_top_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Hb67PDeku2u8",
        "outputId": "85a7c90c-010d-4b14-dba2-3c5645469ef1"
      },
      "outputs": [],
      "source": [
        "# @title Chart 1: Temporal distribution of tweets\n",
        "df['created_at'] = df['created_at'].astype(str).str[:10]\n",
        "df['created_at'] = pd.to_datetime(df['created_at'])\n",
        "\n",
        "df_group = df.groupby('created_at')['text'].count().to_frame(name='count')\n",
        "df_group = df_group.reset_index()\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(x=df_group['created_at'],\n",
        "                y=df_group['count'],\n",
        "                marker_color='rgb(55, 83, 109)'\n",
        "                ))\n",
        "fig.update_layout(title_text='Temporal distribution of tweets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "SNSgRbeivEyF",
        "outputId": "71a46fd8-f82c-49f5-fbc3-e0107ba4445e"
      },
      "outputs": [],
      "source": [
        "# @title Chart 2: Temporal distribution of tweets by month\n",
        "df_month = df_group\n",
        "df_month['created_at'] = df_month['created_at'].astype(str).str[:7]\n",
        "df_month = df_month.groupby('created_at')['count'].sum().to_frame(name='count_month')\n",
        "df_month = df_month.reset_index()\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(x=df_month['created_at'],\n",
        "                y=df_month['count_month'],\n",
        "                marker_color='rgb(55, 83, 109)'\n",
        "                ))\n",
        "fig.update_layout(title_text='Temporal distribution of tweets per month')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "0FQQJjVavO5C",
        "outputId": "67d312d3-fe34-4939-a637-0d6259ff2181"
      },
      "outputs": [],
      "source": [
        "# @title Chart 3: Temporal distribution of tweets by user (per month)\n",
        "user = 'fdp' # @param {type:\"string\"}\n",
        "pd.set_option('mode.chained_assignment', None)\n",
        "df_user = df[df['user_username'] == user]\n",
        "df_user['created_at'] = df_user['created_at'].astype(str).str[:7]\n",
        "df_user = df_user.groupby('created_at')['text'].count().to_frame(name='count')\n",
        "df_user = df_user.reset_index()\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(x=df_user['created_at'],\n",
        "                y=df_user['count'],\n",
        "                marker_color='rgb(55, 83, 109)'\n",
        "                ))\n",
        "fig.update_layout(title_text='Temporal distribution of tweets for user: ' + user)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "w_aMYZH2vRR-",
        "outputId": "751623e2-48ad-4e64-d905-77175f6abbab"
      },
      "outputs": [],
      "source": [
        "# @title Chart 4: Temporal distribution of tweets by cluster (per month)\n",
        "\n",
        "df_orange = df[df['cluster'] == 'orange']\n",
        "df_red = df[df['cluster'] == 'red']\n",
        "df_green = df[df['cluster'] == 'green']\n",
        "df_grey= df[df['cluster'] == 'gray']\n",
        "\n",
        "df_orange['created_at'] = df_orange['created_at'].astype(str).str[:7]\n",
        "df_red['created_at'] = df_red['created_at'].astype(str).str[:7]\n",
        "df_green['created_at'] = df_green['created_at'].astype(str).str[:7]\n",
        "df_grey['created_at'] = df_grey['created_at'].astype(str).str[:7]\n",
        "\n",
        "df_orange = df_orange.groupby('created_at')['text'].count().to_frame(name='count')\n",
        "df_red = df_red.groupby('created_at')['text'].count().to_frame(name='count')\n",
        "df_green = df_green.groupby('created_at')['text'].count().to_frame(name='count')\n",
        "df_grey = df_grey.groupby('created_at')['text'].count().to_frame(name='count')\n",
        "\n",
        "df_orange = df_orange.reset_index()\n",
        "df_red = df_red.reset_index()\n",
        "df_green = df_green.reset_index()\n",
        "df_grey = df_grey.reset_index()\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(x=df_orange['created_at'],\n",
        "                y=df_orange['count'],\n",
        "                marker_color='orange',\n",
        "                ))\n",
        "fig.add_trace(go.Bar(x=df_red['created_at'],\n",
        "                y=df_red['count'],\n",
        "                marker_color='red'\n",
        "                ))\n",
        "fig.add_trace(go.Bar(x=df_green['created_at'],\n",
        "                y=df_green['count'],\n",
        "                marker_color='green'\n",
        "                ))\n",
        "fig.add_trace(go.Bar(x=df_grey['created_at'],\n",
        "                y=df_grey['count'],\n",
        "                marker_color='grey'\n",
        "                ))\n",
        "fig.update_layout(title_text='Temporal distribution of tweets by cluster (per month)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "vHrXuFOuxH9R",
        "outputId": "27d4a60b-9b3d-44cd-9d9b-349903c54c6b"
      },
      "outputs": [],
      "source": [
        "# @title Chart 5: Likes and Retweets of Tweets Over Time\n",
        "\n",
        "fig = px.scatter(df, x=\"created_at\", y=\"like_count\", size=\"retweet_count\", color=\"cluster\", hover_name=\"user_username\",\n",
        "                 title=\"Likes and Retweets of Tweets Over Time\")\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis_title=\"Number of Likes\",\n",
        "    legend_title=\"Cluster\",\n",
        ")\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOyDksgeKo2olPRM8E3EAsZ",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
