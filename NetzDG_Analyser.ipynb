{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caiocmello/netzdg/blob/main/NetzDG_Analyser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **NetzDG Analyser**\n",
        "This notebook facilitates exploring the data on NetzDG data. Dataset to be used is 'df_netzdg_blue&purple.csv'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LPcWB1TGBda"
      },
      "source": [
        "### Install and import: Run this cell to load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PSuIv2rD9Vv"
      },
      "outputs": [],
      "source": [
        "# @title Load Libraries and Data\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import spacy\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import re\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "from spacy.lang.en.stop_words import STOP_WORDS as en_stopwords\n",
        "from spacy.lang.de.stop_words import STOP_WORDS as de_stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import ngrams\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "# Load the data frame into colab\n",
        "url = 'df_netzdg_blue&purple.csv'\n",
        "df = pd.read_csv(url,index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8UCoFfVsLzi"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(url,index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcAI62DCbXPv"
      },
      "source": [
        "### Data filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dlMtFttnc4ht"
      },
      "outputs": [],
      "source": [
        "# @title Run this cell to see the list of users in dataframe and the number of tweets they posted\n",
        "df['user_username'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nORKFpbPE0CI"
      },
      "outputs": [],
      "source": [
        "# @title Choose a user to see tweets written by them\n",
        "user = \"golem\" # @param {type:\"string\"} # Define word here\n",
        "\n",
        "# See only tweets written by @user\n",
        "\n",
        "def show_rows_with_user(df, user):\n",
        "\n",
        "  return df[df['user_username'] == user]\n",
        "\n",
        "result = show_rows_with_user(df, user)\n",
        "result = result.sort_values(by=['retweet_count'], ascending=False)\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4Z3xbHiaUk0"
      },
      "source": [
        "### List of n-grams\n",
        "\n",
        "* **user:** *user name*\n",
        "* **cluster:** blue or purple\n",
        "* **content:** all, per_user or per_cluster\n",
        "* **items_in_list:** *number*\n",
        "* **see_top_words:** unigrams or bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZwM--MncMOYS"
      },
      "outputs": [],
      "source": [
        "# @title Set parameters to see list of n-grams\n",
        "\n",
        "\n",
        "df_NetzClean = df.copy()\n",
        "\n",
        "# Remove underscore from tweets (To avoid erros in deleting users like @balzer_sascha)\n",
        "\n",
        "def cleaner(text):\n",
        "    text = re.sub(r\"_\", \"\", text) # Remove underscore\n",
        "    return text\n",
        "df_NetzClean['text_clean'] = df_NetzClean['text'].map(lambda x: cleaner(x))\n",
        "\n",
        "# Remove users, remove URLs, remove hashtag sign\n",
        "\n",
        "def cleaner(text):\n",
        "    text = re.sub(\"@[A-Za-z0-9]+\",\"\",text) # Remove @ sign\n",
        "    text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", text) # Remove http links\n",
        "    text = \" \".join(text.split())\n",
        "    text = text.replace(\"#\", \"\") # Remove hashtag sign but keep the text\n",
        "    return text\n",
        "df_NetzClean['text_clean'] = df_NetzClean['text'].map(lambda x: cleaner(x))\n",
        "\n",
        "df_NetzClean = df_NetzClean.drop_duplicates(subset=['text']) #remove duplicated tweets in column 'text'\n",
        "\n",
        "def get_top_n_words(corpus, stopwords, n=20):\n",
        "    vec = CountVectorizer(stop_words = stopwords).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "\n",
        "def get_top_n_bigram(corpus, stopwords, n=20):\n",
        "    vec = CountVectorizer(ngram_range=(2, 2), stop_words = stopwords).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "\n",
        "def get_top_n_words_tfidf(corpus, stopwords, n=20):\n",
        "    vec = TfidfVectorizer(stop_words = stopwords).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "\n",
        "def get_top_n_bigram_tfidf(corpus, stopwords, n=20):\n",
        "    vec = TfidfVectorizer(ngram_range=(2, 2), stop_words = stopwords).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "\n",
        "# Transform stopwords in a list\n",
        "\n",
        "stopwords_de = list(de_stopwords)\n",
        "stopwords_en = list(en_stopwords)\n",
        "\n",
        "stopwords = stopwords_de + stopwords_en #create a mixed list of stopwords (German and English)\n",
        "\n",
        "# Edit your list of stopwords manually\n",
        "\n",
        "add_to_stopwords = ['rt']\n",
        "stopwords = stopwords + add_to_stopwords\n",
        "\n",
        "# Define content\n",
        "user = 'netzpolitik' # @param {type:\"string\"}\n",
        "cluster = 'blue' # @param {type:\"string\"}\n",
        "all = df_NetzClean[['text_clean']]\n",
        "df_user = df_NetzClean[df_NetzClean['user_username'] == user]\n",
        "per_user = df_user[['text_clean']]\n",
        "df_cluster = df_NetzClean[df_NetzClean['cluster'] == cluster]\n",
        "per_cluster = df_cluster[['text_clean']]\n",
        "\n",
        "content = all # @param {type:\"raw\"}\n",
        "content.reset_index(drop=True, inplace=True)\n",
        "content = content.values.tolist()\n",
        "\n",
        "string = '\\n'.join(str(e) for e in content)\n",
        "\n",
        "items_in_list = 10 # @param {type:\"number\"}\n",
        "\n",
        "unigrams = get_top_n_words([string], stopwords=stopwords, n=items_in_list)\n",
        "bigrams = get_top_n_bigram([string], stopwords=stopwords, n=items_in_list)\n",
        "see_top_words = bigrams # @param {type:\"raw\"}\n",
        "\n",
        "see_top_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljtubHIErHFc"
      },
      "source": [
        "## **Visualisation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "cvXuk1rFr8Xi",
        "outputId": "9ce9d1ce-18e7-4842-b52b-5cf1513b75ac"
      },
      "outputs": [],
      "source": [
        "# @title Chart 1: Temporal distribution of tweets\n",
        "df['created_at'] = df['created_at'].astype(str).str[:10]\n",
        "df['created_at'] = pd.to_datetime(df['created_at'])\n",
        "\n",
        "df_group = df.groupby('created_at')['text'].count().to_frame(name='count')\n",
        "df_group = df_group.reset_index()\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(x=df_group['created_at'],\n",
        "                y=df_group['count'],\n",
        "                marker_color='rgb(55, 83, 109)'\n",
        "                ))\n",
        "fig.update_layout(title_text='Temporal distribution of tweets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ji6mWZWuyoQx",
        "outputId": "72632916-8f1d-404e-b01a-78839bb72576"
      },
      "outputs": [],
      "source": [
        "# @title Chart 2: Temporal distribution of tweets by month\n",
        "df_month = df_group\n",
        "df_month['created_at'] = df_month['created_at'].astype(str).str[:7]\n",
        "df_month = df_month.groupby('created_at')['count'].sum().to_frame(name='count_month')\n",
        "df_month = df_month.reset_index()\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(x=df_month['created_at'],\n",
        "                y=df_month['count_month'],\n",
        "                marker_color='rgb(55, 83, 109)'\n",
        "                ))\n",
        "fig.update_layout(title_text='Temporal distribution of tweets per month')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "gYIR45iA1MDM",
        "outputId": "bd4219dc-8d68-4b17-fdc0-1e1c0903d62e"
      },
      "outputs": [],
      "source": [
        "# @title Chart 3: Temporal distribution of tweets by user (per month)\n",
        "user = 'netzpolitik' # @param {type:\"string\"}\n",
        "pd.set_option('mode.chained_assignment', None)\n",
        "df_user = df[df['user_username'] == user]\n",
        "df_user['created_at'] = df_user['created_at'].astype(str).str[:7]\n",
        "df_user = df_user.groupby('created_at')['text'].count().to_frame(name='count')\n",
        "df_user = df_user.reset_index()\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(x=df_user['created_at'],\n",
        "                y=df_user['count'],\n",
        "                marker_color='rgb(55, 83, 109)'\n",
        "                ))\n",
        "fig.update_layout(title_text='Temporal distribution of tweets for user: ' + user)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "6KqBR1sBCHLd",
        "outputId": "ad1dcb7d-398c-4a2b-b8ab-0595923afb68"
      },
      "outputs": [],
      "source": [
        "# @title Chart 4: Temporal distribution of tweets by cluster (per month)\n",
        "\n",
        "df_blue = df[df['cluster'] == 'blue']\n",
        "df_purple = df[df['cluster'] == 'purple']\n",
        "\n",
        "df_blue['created_at'] = df_blue['created_at'].astype(str).str[:7]\n",
        "df_purple['created_at'] = df_purple['created_at'].astype(str).str[:7]\n",
        "\n",
        "df_blue = df_blue.groupby('created_at')['text'].count().to_frame(name='count')\n",
        "df_purple = df_purple.groupby('created_at')['text'].count().to_frame(name='count')\n",
        "\n",
        "df_blue = df_blue.reset_index()\n",
        "df_purple = df_purple.reset_index()\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(x=df_blue['created_at'],\n",
        "                y=df_blue['count'],\n",
        "                marker_color='#0073e6'\n",
        "                ))\n",
        "fig.add_trace(go.Bar(x=df_purple['created_at'],\n",
        "                y=df_purple['count'],\n",
        "                marker_color='#9B8BF4'\n",
        "                ))\n",
        "fig.update_layout(title_text='Temporal distribution of tweets by cluster (per month)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "_a2l0nSaKbvg",
        "outputId": "61a7b8df-445d-429e-a725-5a7e8a1632a0"
      },
      "outputs": [],
      "source": [
        "# @title Chart 5: Likes and Retweets of Tweets Over Time\n",
        "\n",
        "fig = px.scatter(df, x=\"created_at\", y=\"like_count\", size=\"retweet_count\", color=\"cluster\", hover_name=\"user_username\",\n",
        "                 title=\"Likes and Retweets of Tweets Over Time\")\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis_title=\"Number of Likes\",\n",
        "    legend_title=\"Cluster\",\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfBU9QTGSRr9"
      },
      "source": [
        "## **What happened in January 2018?**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nugjL4k2TZWM"
      },
      "source": [
        "**Statistics:**\n",
        "\n",
        "*   **560** tweets were posted in January 2018 by **27** users\n",
        "*   **13** users belong to cluster blue and **14** to cluster purple\n",
        "*   **234** tweets were posted by cluster: **purple**\n",
        "*   **326** tweets were posted by cluster: **blue**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyeKrY-mrFCW",
        "outputId": "cc75e6b2-349d-48a7-a3bd-d36c29fba2ca"
      },
      "outputs": [],
      "source": [
        "# @title Run this cell to generate data about January 2018\n",
        "\n",
        "df_2018 = df[df['created_at'].astype(str).str.startswith('2018-01')]\n",
        "print('Complete!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SAGI3N2cWNeU"
      },
      "outputs": [],
      "source": [
        "# @title Number of tweets per user in January 2018\n",
        "\n",
        "df_2018['user_username'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pmd9gJl7XLPX"
      },
      "outputs": [],
      "source": [
        "# @title Set parameters to see list of n-grams for Jan 2018\n",
        "\n",
        "# Remove underscore from tweets (To avoid erros in deleting users like @balzer_sascha)\n",
        "\n",
        "df_2018['text_clean'] = df_2018['text'].map(lambda x: cleaner(x))\n",
        "\n",
        "# Remove users, remove URLs, remove hashtag sign\n",
        "\n",
        "df_2018['text_clean'] = df_2018['text'].map(lambda x: cleaner(x))\n",
        "\n",
        "df_2018 = df_2018.drop_duplicates(subset=['text']) #remove duplicated tweets in column 'text'\n",
        "\n",
        "# Edit your list of stopwords manually\n",
        "\n",
        "add_to_stopwords = ['rt','twitter']\n",
        "stopwords = stopwords + add_to_stopwords\n",
        "\n",
        "# Define content\n",
        "user_2018 = 'netzpolitik' # @param {type:\"string\"}\n",
        "cluster_2018 = 'blue' # @param {type:\"string\"}\n",
        "all_2018 = df_2018[['text_clean']]\n",
        "df_user_2018 = df_2018[df_2018['user_username'] == user_2018]\n",
        "per_user_2018 = df_user_2018[['text_clean']]\n",
        "df_cluster_2018 = df_2018[df_2018['cluster'] == cluster_2018]\n",
        "per_cluster_2018 = df_cluster_2018[['text_clean']]\n",
        "\n",
        "content_2018 = all_2018 # @param {type:\"raw\"}\n",
        "content_2018.reset_index(drop=True, inplace=True)\n",
        "content_2018 = content_2018.values.tolist()\n",
        "\n",
        "string_2018 = '\\n'.join(str(e) for e in content_2018)\n",
        "\n",
        "items_in_list = 20 # @param {type:\"number\"}\n",
        "\n",
        "unigrams_2018 = get_top_n_words([string_2018], stopwords=stopwords, n=items_in_list)\n",
        "bigrams_2018 = get_top_n_bigram([string_2018], stopwords=stopwords, n=items_in_list)\n",
        "see_top_words = bigrams_2018 # @param {type:\"raw\"}\n",
        "\n",
        "see_top_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "U0HVeDrFXLGY"
      },
      "outputs": [],
      "source": [
        "# @title See dataset sorted by like or retweet count\n",
        "sort_by = \"retweet_count\" # @param [\"like_count\",\"retweet_count\"]\n",
        "df_2018.sort_values(by=[sort_by], ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "92VoaYwUXK6H"
      },
      "outputs": [],
      "source": [
        "# @title See dataset sorted by date\n",
        "sort_by = \"created_at\"\n",
        "df_2018.sort_values(by=[sort_by], ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "H8Hvzr49rFAF",
        "outputId": "c4c43023-4fea-45d4-c6a3-c1e140ad3292"
      },
      "outputs": [],
      "source": [
        "# @title Chart 6: Temporal distribution of tweets per day\n",
        "df_2018viz = df_2018.groupby('created_at')['text'].count().to_frame(name='count')\n",
        "df_2018viz = df_2018viz.reset_index()\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(x=df_2018viz['created_at'],\n",
        "                y=df_2018viz['count'],\n",
        "                marker_color='rgb(55, 83, 109)'\n",
        "                ))\n",
        "fig.update_layout(title_text='Temporal distribution of tweets in January 2018')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "868qXBk8oQXI",
        "outputId": "86345c0a-20e0-4b40-e03f-5499639cf33e"
      },
      "outputs": [],
      "source": [
        "# @title Chart 7: Temporal distribution of tweets in Jan 2018 (by user)\n",
        "\n",
        "df_user_date = df_2018.groupby(['created_at', 'user_username'])['text'].count().unstack()\n",
        "fig = px.bar(df_user_date, barmode='stack')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "b592cGHxn7Ar",
        "outputId": "92d3e4a3-b0c4-4a83-e41d-cad07f8ce114"
      },
      "outputs": [],
      "source": [
        "# @title Chart 8: Likes and Retweets of Tweets in Jan 2018\n",
        "\n",
        "fig = px.scatter(df_2018, x=\"created_at\", y=\"like_count\", size=\"retweet_count\", color=\"cluster\", hover_name=\"user_username\",\n",
        "                 title=\"Likes and Retweets of Tweets Over Time\")\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis_title=\"Number of Likes\",\n",
        "    legend_title=\"Cluster\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSfwr7q4G9ir"
      },
      "source": [
        "## **Comparison between June 2017, January 2018 and May 2019**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1lWakdOIS1h"
      },
      "source": [
        "**Statistics:**\n",
        "\n",
        "June 2017:\n",
        "*   **376** tweets were posted in June 2017 by **26** users\n",
        "*   **14** users belong to cluster blue and **12** to cluster purple\n",
        "*   **132** tweets were posted by cluster: **purple**\n",
        "*   **244** tweets were posted by cluster: **blue**\n",
        "\n",
        "\n",
        "January 2018:\n",
        "*   **560** tweets were posted in January 2018 by **27** users\n",
        "*   **13** users belong to cluster blue and **14** to cluster purple\n",
        "*   **234** tweets were posted by cluster: **purple**\n",
        "*   **326** tweets were posted by cluster: **blue**\n",
        "\n",
        "May 2019:\n",
        "*   **74** tweets were posted in May 2019 by **14** users\n",
        "*   **5** users belong to cluster blue and **9** to cluster purple\n",
        "*   **33** tweets were posted by cluster: **purple**\n",
        "*   **41** tweets were posted by cluster: **blue**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtFQDFM7HLr5",
        "outputId": "d4122fe1-a756-481c-cab0-7d6ed9097d5b"
      },
      "outputs": [],
      "source": [
        "# @title Run this cell to generate data about June 2017 and May 2019\n",
        "\n",
        "df_2017 = df[df['created_at'].astype(str).str.startswith('2017-06')]\n",
        "df_2019 = df[df['created_at'].astype(str).str.startswith('2019-05')]\n",
        "print('Complete!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2COPe1rbHfok"
      },
      "outputs": [],
      "source": [
        "# @title Number of tweets per user in June 2017\n",
        "\n",
        "df_2017['user_username'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3bOx1ySZHfx2"
      },
      "outputs": [],
      "source": [
        "# @title Number of tweets per user in May 2019\n",
        "\n",
        "df_2019['user_username'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Vx_KG3E3Hf6e"
      },
      "outputs": [],
      "source": [
        "# @title Set parameters to see list of n-grams for June 2017\n",
        "\n",
        "# Remove underscore from tweets (To avoid erros in deleting users like @balzer_sascha)\n",
        "\n",
        "df_2017['text_clean'] = df_2017['text'].map(lambda x: cleaner(x))\n",
        "\n",
        "# Remove users, remove URLs, remove hashtag sign\n",
        "\n",
        "df_2017['text_clean'] = df_2017['text'].map(lambda x: cleaner(x))\n",
        "\n",
        "df_2017 = df_2017.drop_duplicates(subset=['text']) #remove duplicated tweets in column 'text'\n",
        "\n",
        "# Edit your list of stopwords manually\n",
        "\n",
        "add_to_stopwords = ['rt','twitter']\n",
        "stopwords = stopwords + add_to_stopwords\n",
        "\n",
        "# Define content\n",
        "user_2017 = 'netzpolitik' # @param {type:\"string\"}\n",
        "cluster_2017 = 'blue' # @param {type:\"string\"}\n",
        "all_2017 = df_2017[['text_clean']]\n",
        "df_user_2017 = df_2017[df_2017['user_username'] == user_2017]\n",
        "per_user_2017 = df_user_2017[['text_clean']]\n",
        "df_cluster_2017 = df_2017[df_2017['cluster'] == cluster_2017]\n",
        "per_cluster_2017 = df_cluster_2017[['text_clean']]\n",
        "\n",
        "content_2017 = all_2017 # @param {type:\"raw\"}\n",
        "content_2017.reset_index(drop=True, inplace=True)\n",
        "content_2017 = content_2017.values.tolist()\n",
        "\n",
        "string_2017 = '\\n'.join(str(e) for e in content_2017)\n",
        "\n",
        "items_in_list = 20 # @param {type:\"number\"}\n",
        "\n",
        "unigrams_2017 = get_top_n_words([string_2017], stopwords=stopwords, n=items_in_list)\n",
        "bigrams_2017 = get_top_n_bigram([string_2017], stopwords=stopwords, n=items_in_list)\n",
        "see_top_words = bigrams_2017 # @param {type:\"raw\"}\n",
        "\n",
        "see_top_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "T-cCZUn1Hf9J"
      },
      "outputs": [],
      "source": [
        "# @title Set parameters to see list of n-grams for May 2019\n",
        "\n",
        "# Remove underscore from tweets (To avoid erros in deleting users like @balzer_sascha)\n",
        "\n",
        "df_2019['text_clean'] = df_2019['text'].map(lambda x: cleaner(x))\n",
        "\n",
        "# Remove users, remove URLs, remove hashtag sign\n",
        "\n",
        "df_2019['text_clean'] = df_2019['text'].map(lambda x: cleaner(x))\n",
        "\n",
        "df_2019 = df_2019.drop_duplicates(subset=['text']) #remove duplicated tweets in column 'text'\n",
        "\n",
        "# Edit your list of stopwords manually\n",
        "\n",
        "add_to_stopwords = ['rt','twitter']\n",
        "stopwords = stopwords + add_to_stopwords\n",
        "\n",
        "# Define content\n",
        "user_2019 = 'netzpolitik' # @param {type:\"string\"}\n",
        "cluster_2019 = 'blue' # @param {type:\"string\"}\n",
        "all_2019 = df_2019[['text_clean']]\n",
        "df_user_2019 = df_2019[df_2019['user_username'] == user_2019]\n",
        "per_user_2019 = df_user_2019[['text_clean']]\n",
        "df_cluster_2019 = df_2019[df_2019['cluster'] == cluster_2019]\n",
        "per_cluster_2019 = df_cluster_2019[['text_clean']]\n",
        "\n",
        "content_2019 = all_2019 # @param {type:\"raw\"}\n",
        "content_2019.reset_index(drop=True, inplace=True)\n",
        "content_2019 = content_2019.values.tolist()\n",
        "\n",
        "string_2019 = '\\n'.join(str(e) for e in content_2019)\n",
        "\n",
        "items_in_list = 20 # @param {type:\"number\"}\n",
        "\n",
        "unigrams_2019 = get_top_n_words([string_2019], stopwords=stopwords, n=items_in_list)\n",
        "bigrams_2019 = get_top_n_bigram([string_2019], stopwords=stopwords, n=items_in_list)\n",
        "see_top_words = bigrams_2019 # @param {type:\"raw\"}\n",
        "\n",
        "see_top_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "MY3g8Mn5NGxU",
        "outputId": "07e4c90c-dc46-4671-b6ea-4cb0bf0ad6aa"
      },
      "outputs": [],
      "source": [
        "# @title Chart 9: Temporal distribution of tweets in June 2017 (by user)\n",
        "\n",
        "df_user_date7 = df_2017.groupby(['created_at', 'user_username'])['text'].count().unstack()\n",
        "fig = px.bar(df_user_date7, barmode='stack')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Fuk9O61NNVwV",
        "outputId": "e023eee1-3b7f-4c5b-d6d8-b295f245629c"
      },
      "outputs": [],
      "source": [
        "# @title Chart 10: Temporal distribution of tweets in May 2019 (by user)\n",
        "\n",
        "df_user_date9 = df_2019.groupby(['created_at', 'user_username'])['text'].count().unstack()\n",
        "fig = px.bar(df_user_date9, barmode='stack')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gkq1OPtuU1FX"
      },
      "outputs": [],
      "source": [
        "df.sort_values(by=['retweet_count'], ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdZOwI5-Hhj1"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
