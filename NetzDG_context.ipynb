{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caiocmello/netzdg/blob/main/NetzDG_context.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **NetzDG Context**\n",
        "This notebook facilitates exploring the context of debates on NetzDG data. Datasets to be used are two:\n",
        "1. 'df_netzdg_blue&purple.csv'\n",
        "2. 'df_colours.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhYCUfaB2gZG"
      },
      "outputs": [],
      "source": [
        "# @title Run this cell to load the necessary libraries and data\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import spacy\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import re\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "from spacy.lang.en.stop_words import STOP_WORDS as en_stopwords\n",
        "from spacy.lang.de.stop_words import STOP_WORDS as de_stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import ngrams\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "# Load the data frame into colab\n",
        "#url = ('/Users/caio.mello/Documents/NetzDG_project/NetzDG_data/df_netzdg_blue&purple.csv')\n",
        "url = 'df_netzdg_blue&purple.csv'\n",
        "df = pd.read_csv(url,index_col=0)\n",
        "#df_colours = pd.read_csv('/Users/caio.mello/Documents/NetzDG_project/NetzDG_data/df_colours.csv', encoding='latin1')\n",
        "file_id = '1NJBXn4o4TBA6mh1gbABjEtUwZRHczstW'\n",
        "url2 = f'https://drive.google.com/uc?id={file_id}'\n",
        "df_colours = pd.read_csv(url2, encoding='latin1')\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "# prompt: remove duplicated values in column 'text'\n",
        "df.drop_duplicates(subset='text', inplace=True)\n",
        "df_colours.drop_duplicates(subset='text', inplace=True)\n",
        "df_colours = df_colours[['user_username', 'text','retweet_count', 'like_count', 'created_at', 'cluster']]\n",
        "conc_df = pd.concat([df, df_colours], axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XxTxUf48Avm"
      },
      "source": [
        "## Context Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1133
        },
        "id": "Mx82HgQv7kmW",
        "outputId": "fd1fe1b2-e140-464d-e503-b3b014b096ba"
      },
      "outputs": [],
      "source": [
        "# @title Choose a word to see context (PS: if column 'word' is 'None', word is probably used as hashtag in text)\n",
        "word = \"Freiheit\" # @param {type:\"string\"}\n",
        "\n",
        "sentences_with_word = conc_df[conc_df['text'].str.contains(word, case=False, na=False)]\n",
        "\n",
        "# Split the sentences at the word 'x'\n",
        "split_sentences = sentences_with_word['text'].str.split(word, n=1, expand=True)\n",
        "\n",
        "# Rename the columns\n",
        "split_sentences.columns = ['Before', 'After']\n",
        "split_sentences.insert(1, 'word', word)\n",
        "split_sentences['word'] = split_sentences.apply(lambda row: 'None' if pd.isnull(row['After']) else row['word'], axis=1)\n",
        "#split_sentences\n",
        "merged_df = pd.concat([split_sentences, conc_df], axis=1)\n",
        "merged_df = merged_df[['user_username','Before', 'word', 'After', 'retweet_count', 'like_count', 'created_at', 'cluster']]\n",
        "merged_df = merged_df.reset_index()\n",
        "merged_df = merged_df.drop(columns=['index'])\n",
        "merged_df = merged_df.dropna(subset=['Before'])\n",
        "merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count how many tweets were posted by user containing the above searched word \n",
        "merged_df['user_username'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "UtWkJ7rfGsjY",
        "outputId": "0e79ddab-7172-4870-93a6-b04667db529f"
      },
      "outputs": [],
      "source": [
        "# @title Generate a wordcloud with the most mentioned words in text where the word chosen above is mentioned\n",
        "# prompt: create a wordcloud with words mentioned in column 'text' when word 'Zensur' is found\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "stopwords_de = list(de_stopwords)\n",
        "stopwords_en = list(en_stopwords)\n",
        "stopwords = stopwords_de + stopwords_en #create a mixed list of stopwords (German and English)\n",
        "# Edit your list of stopwords manually\n",
        "add_to_stopwords = ['rt', 'https', 't', 'co']\n",
        "stopwords = stopwords + add_to_stopwords\n",
        "\n",
        "sentences_with_word = conc_df[conc_df['text'].str.contains(word, case=False, na=False)]\n",
        "text = \" \".join(sentences_with_word['text'].tolist())\n",
        "\n",
        "wordcloud = WordCloud(width=800, height=600, background_color='white', stopwords=stopwords).generate(text)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "NFHjtoqW_1PE",
        "outputId": "65ef8227-fe14-44f6-b0bb-9e748a8ef199"
      },
      "outputs": [],
      "source": [
        "# @title Choose a word to see context per cluster (blue or purple)\n",
        "cluster = 'orange' # @param {type:\"string\"}\n",
        "\n",
        "df_cluster = conc_df[conc_df['cluster'] == cluster]\n",
        "sentences_with_word_cluster = df_cluster[df_cluster['text'].str.contains(word, case=False, na=False)]\n",
        "\n",
        "# Split the sentences at the word 'x'\n",
        "split_sentences_cluster = sentences_with_word_cluster['text'].str.split(word, n=1, expand=True)\n",
        "\n",
        "# Rename the columns\n",
        "split_sentences_cluster.columns = ['Before', 'After']\n",
        "split_sentences_cluster.insert(1, 'word', word)\n",
        "split_sentences_cluster['word'] = split_sentences_cluster.apply(lambda row: 'None' if pd.isnull(row['After']) else row['word'], axis=1)\n",
        "split_sentences_cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "DUmNRwcCSIdg",
        "outputId": "d00bae76-22c5-49e9-f152-d9e3926db015"
      },
      "outputs": [],
      "source": [
        "# @title Generate a wordcloud for BLUE\n",
        "# prompt: create a wordcloud with words mentioned in column 'text' when word 'Zensur' is found\n",
        "\n",
        "df_blue = conc_df[conc_df['cluster'] == 'blue']\n",
        "df_purple = conc_df[conc_df['cluster'] == 'purple']\n",
        "sentences_with_word_blue = df_blue[df_blue['text'].str.contains(word, case=False, na=False)]\n",
        "sentences_with_word_purple = df_purple[df_purple['text'].str.contains(word, case=False, na=False)]\n",
        "\n",
        "text_blue = \" \".join(sentences_with_word_blue['text'].tolist())\n",
        "text_purple = \" \".join(sentences_with_word_purple['text'].tolist())\n",
        "\n",
        "wordcloud_b = WordCloud(width=800, height=600, background_color='white', stopwords=stopwords).generate(text_blue)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud_b, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "x__cEAjPUqnq",
        "outputId": "edc162b4-8262-44bf-80f8-f23e807b9b25"
      },
      "outputs": [],
      "source": [
        "# @title Generate a wordcloud for PURPLE\n",
        "wordcloud_p = WordCloud(width=800, height=600, background_color='white', stopwords=stopwords).generate(text_purple)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(wordcloud_p, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_VFkMp4VDiL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM9ThBX0z62N8Jf67e953/Z",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
